{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z89NDA-ToPnT"
      },
      "source": [
        "In this notebook, let us see how we can represent text using pre-trained word embedding models. \n",
        "\n",
        "# 1. Using a pre-trained word2vec model\n",
        "\n",
        "Let us take an example of a pre-trained word2vec model, and how we can use it to look for most similar words. We will use the Google News vectors embeddings.\n",
        "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "\n",
        "A few other pre-trained word embedding models, and details on the means to access them through gensim can be found in:\n",
        "https://github.com/RaRe-Technologies/gensim-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0LLCGJyjykp",
        "outputId": "baa01bd0-27aa-47fc-e81b-018daad13864"
      },
      "outputs": [],
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# !pip install scikit-learn==0.21.3\n",
        "# !pip install wget==3.2\n",
        "# !pip install gensim==3.6.0\n",
        "# !pip install psutil==5.4.8\n",
        "# !pip install spacy==2.2.4\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeptSAcnjykr"
      },
      "outputs": [],
      "source": [
        "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# try :\n",
        "#     import google.colab\n",
        "#     !curl https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch3/ch3-requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# except ModuleNotFoundError :\n",
        "#     !pip install -r \"ch3-requirements.txt\"\n",
        "\n",
        "# ==========================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:45:44.132578Z",
          "start_time": "2021-04-03T11:45:44.115562Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTpzLd6dvB6Q",
        "outputId": "c1b88fb2-f952-4d54-c981-5bd339a7ec03"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
        "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
        "    if not os.path.exists(\"../Ch2/GoogleNews-vectors-negative300.bin\"):\n",
        "        #Downloading the reqired model\n",
        "        if not os.path.exists(\"../Ch2/GoogleNews-vectors-negative300.bin.gz\"):\n",
        "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
        "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
        "            gn_vec_zip_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "        else:\n",
        "            gn_vec_zip_path = \"../Ch2/GoogleNews-vectors-negative300.bin.gz\"\n",
        "        #Extracting the required model\n",
        "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
        "            with open(gn_vec_path, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    else:\n",
        "        gn_vec_path = \"../Ch2/\" + gn_vec_path\n",
        "\n",
        "print(f\"Model at {gn_vec_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:45:54.417319Z",
          "start_time": "2021-04-03T11:45:54.388099Z"
        },
        "id": "ZBsTuJ5FwAFm"
      },
      "outputs": [],
      "source": [
        "import warnings #This module ignores the various types of warnings generated\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "\n",
        "import psutil #This module helps in retrieving information on running processes and system resource utilization\n",
        "process = psutil.Process(os.getpid())\n",
        "from psutil import virtual_memory\n",
        "mem = virtual_memory()\n",
        "\n",
        "import time #This module is used to calculate the time  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:46:20.532122Z",
          "start_time": "2021-04-03T11:46:04.765309Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aodBmqZToPnY",
        "outputId": "92d33173-474b-4a43-b69d-9cb7b25f81f3"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "pretrainedpath = gn_vec_path\n",
        "\n",
        "#Load W2V model. This will take some time, but it is a one time effort! \n",
        "pre = process.memory_info().rss\n",
        "print(\"Memory used in GB before Loading the Model: %0.2f\"%float(pre/(10**9))) #Check memory usage before loading the model\n",
        "print('-'*10)\n",
        "\n",
        "start_time = time.time() #Start the timer\n",
        "ttl = mem.total #Toal memory available\n",
        "\n",
        "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) #load the model\n",
        "print(\"%0.2f seconds taken to load\"%float(time.time() - start_time)) #Calculate the total time elapsed since starting the timer\n",
        "print('-'*10)\n",
        "\n",
        "print('Finished loading Word2Vec')\n",
        "print('-'*10)\n",
        "\n",
        "post = process.memory_info().rss\n",
        "print(\"Memory used in GB after Loading the Model: {:.2f}\".format(float(post/(10**9)))) #Calculate the memory used after loading the model\n",
        "print('-'*10)\n",
        "\n",
        "print(\"Percentage increase in memory usage: {:.2f}% \".format(float((post/pre)*100))) #Percentage increase in memory after loading the model\n",
        "print('-'*10)\n",
        "\n",
        "print(\"Numver of words in vocablulary: \",len(w2v_model)) #Number of words in the vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:46:29.336184Z",
          "start_time": "2021-04-03T11:46:26.529524Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhJ_488PoPnr",
        "outputId": "2e814190-7f09-40a9-acd3-1ec359e90bfd"
      },
      "outputs": [],
      "source": [
        "#Let us examine the model by knowing what the most similar words are, for a given word!\n",
        "w2v_model.most_similar('beautiful')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:46:29.509126Z",
          "start_time": "2021-04-03T11:46:29.337187Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1Or5oG5oPn1",
        "outputId": "a74b5481-2016-4374-ddf4-1f1c73ad5259"
      },
      "outputs": [],
      "source": [
        "#Let us try with another word! \n",
        "w2v_model.most_similar('toronto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:46:30.275722Z",
          "start_time": "2021-04-03T11:46:30.266713Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtQiYOR9oPn_",
        "outputId": "8ff4dadf-5548-4236-d732-a12e346ebbce"
      },
      "outputs": [],
      "source": [
        "#What is the vector representation for a word? \n",
        "w2v_model['computer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:46:34.146257Z",
          "start_time": "2021-04-03T11:46:34.090646Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "RoeH_gfroPoJ",
        "outputId": "18647ecc-ea7f-4bb7-8d92-baa3fc0f0773"
      },
      "outputs": [],
      "source": [
        "#What if I am looking for a word that is not in this vocabulary?\n",
        "w2v_model['practicalnlp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "douwnKS5oPoS"
      },
      "source": [
        "#### Two things to note while using pre-trained models: \n",
        "\n",
        "\n",
        "1.   Tokens/Words are always lowercased. If a word is not in the vocabulary,   the model throws an exception.\n",
        "2.   So, it is always a good idea to encapsulate those statements in try/except blocks.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjWxh9kBoPob"
      },
      "source": [
        "# 2. Getting the embedding representation for full text\n",
        "\n",
        "We have seen how to get embedding vectors for single words. How do we use them to get such a representation for a full text? A simple way is to just sum or average the embeddings for individual words. We will see an example of this using Word2Vec in Chapter 4. Let us see a small example using another NLP library Spacy - which we saw earlier in Chapter 2 too.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:47:53.423180Z",
          "start_time": "2021-04-03T11:47:38.167565Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_g9XOY9jykw",
        "outputId": "19af4a80-b732-4ac9-e3d0-f55d723b7999",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:48:08.393199Z",
          "start_time": "2021-04-03T11:47:59.993770Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFLuSb9ZoPoc",
        "outputId": "4a947d2f-55ee-40a5-f3be-f990b486ba05"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "%time \n",
        "nlp = spacy.load('en_core_web_md')\n",
        "# process a sentence using the model\n",
        "mydoc = nlp(\"Canada is a large country\")\n",
        "#Get a vector for individual words\n",
        "#print(doc[0].vector) #vector for 'Canada', the first word in the text \n",
        "print(mydoc.vector) #Averaged vector for the entire sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:48:15.507141Z",
          "start_time": "2021-04-03T11:48:15.489118Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-8wrQlLoPol",
        "outputId": "e0bd5cd4-6c37-473c-8f8a-ed90268c982e"
      },
      "outputs": [],
      "source": [
        "#What happens when I give a sentence with strange words (and stop words), and try to get its word vector in Spacy?\n",
        "temp = nlp('practicalnlp is a newword')\n",
        "temp[0].vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2PSThugoPos"
      },
      "source": [
        "Well, at least, this is better than throwing an exception! :) \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "05_Pre_Trained_Word_Embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
